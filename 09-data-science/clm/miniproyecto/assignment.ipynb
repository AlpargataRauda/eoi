{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproyecto - Ciencia de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "\n",
    "La tarea consiste en analizar y explorar un conjunto de datos sencillo, utilizando las herramientas vistas en clase: `numpy`, `pandas`, `matplotlib`, `scikit-learn`, etc.\n",
    "\n",
    "El conjunto de datos está en formato CSV, y se puede descargar [aquí](https://storage.googleapis.com/curso-eoi/sales.csv).\n",
    "\n",
    "Cada fila del conjunto de datos describe una campaña de marketing con la cantidad de dinero que una empresa no especificada ha empleado en tres canales diferentes: televisión, radio y prensa, además de una última columna que lista las ventas conseguidas en dicha campaña. Las columnas `TV`, `radio` y `newspaper` indican la cantidad de dinero invertida en miles de euros, mientras que la columna `sales` indica miles de unidades vendidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1\n",
    "\n",
    "* Limpiar el conjunto de datos de aquellas filas en las que falten datos o haya valores extraños o fuera de rango (recordemos [`pandas.DataFrame.describe()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html))\n",
    "* Crear tres scatter plots (o uno solo con tres subplots) con los ejes debidamente etiquetados, donde el eje X es la cantidad de dinero invertida en ese canal, y el eje Y representa el número de unidades vendidas\n",
    "* **[OPCIONAL]** Utilizar una librería de plotting alternativa, como por ejemplo [`seaborn.regplot()`](https://seaborn.pydata.org/generated/seaborn.regplot.html); este incluye automáticamente una recta de regresión sobre los datos y unos intervalos de confianza ajustables\n",
    "* **[OPCIONAL]** Investigar acerca del coeficiente de correlación de Pearson (por ejemplo [aquí](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) y [aquí](https://realpython.com/numpy-scipy-pandas-correlation-python/)), calcularlo y mostrarlo sobre los plots. La funcion [`numpy.corrcoef()`](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html) es útil para esto\n",
    "\n",
    "El resultado debe ser similar a esto:\n",
    "\n",
    "![Plots](data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2\n",
    "\n",
    "Aumentar el dataset con las siguientes dos columnas generadas:\n",
    "\n",
    "* Cantidad total invertida por venta, es decir, coste total (entre los tres canales) dividido por el número de ventas\n",
    "* Un valor booleano (`true`/`false`, o `0`/`1`) que indique si la campaña de marketing fue _exitosa_. Una campaña es considerada exitosa si se cumplen **ambas** condiciones siguientes:\n",
    "    * Cantidad total invertida por venta es menos de 20€\n",
    "    * Más de 15000 unidades fueron vendidas\n",
    "\n",
    "Responder a la pregunta: **¿Cuántas campañas fueron exitosas?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3\n",
    "\n",
    "* Crear un conjunto de entrenamiento seleccionando las filas con `id <= 160`. Leer atentamente los parámetros de [`sklearn.model_selection.train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) para hacer esto.\n",
    "* Entrenar un clasificador [_Gaussian Naive-Bayes_](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) para determinar si una campaña será exitosa dadas las cantidades empleadas en cada canal de marketing. Este clasificador se usa de manera similar a otros que vimos en clase (utiliza los mismos métodos `fit()`, `predict()`, etc.) y es difícil de utilizar incorrectamente ya que no hace falta configurar ningún hiperparámetro.\n",
    "* Calcular la fracción del conjunto de entrenamiento que es clasificado correctamente, es decir, aplicar el modelo entrenado con el conjunto de entrenamiento sobre sí mismo. Para ello se puede usar el método `score()` del modelo, que internamente llama a [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).\n",
    "* **[OPCIONAL]** Utilizar clasificadores alternativos, tales como regresión logística ([enlace](https://realpython.com/logistic-regression-python/), [enlace](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)) o random forest ([enlace](https://www.datacamp.com/community/tutorials/random-forests-classifier-python), [enlace](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4\n",
    "\n",
    "* Crear un conjunto de prueba seleccionando las filas con `id > 160`. Misma idea que en el paso anterior.\n",
    "* Evaluar el rendimiento del clasificador de la siguiente manera:\n",
    "    * ¿Qué porcentaje del conjunto de prueba fue clasificado correctamente (aciertos sobre el total)? Es deseable que este número llegue al menos al 80%\n",
    "    * ¿Cuál es el número de [falsos positivos y falsos negativos](https://en.wikipedia.org/wiki/False_positives_and_false_negatives)? ¿Cuál es la proporción de cada uno de ellos sobre el total de predicciones? Para esto es útil explorar la [matriz de confusión](https://en.wikipedia.org/wiki/Confusion_matrix) con [`sklearn.metrics.confusion_matrix()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) y la puntuación de precisión con [`sklearn.metrics.precision_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterios de evaluación\n",
    "\n",
    "En orden de importancia, se evaluará la entrega acorde a los siguientes puntos:\n",
    "\n",
    "1. **<ins>Implementación de los puntos obligatorios en los cuatro pasos</ins>**\n",
    "2. **<ins>Correctitud de los datos obtenidos</ins>**\n",
    "3. **<ins>Implementación de los puntos opcionales</ins>**\n",
    "4. **<ins>Organización y limpieza del código</ins>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fecha límite de entrega\n",
    "\n",
    "La tarea deberá ser entregada, a más tardar, el **miércoles 23 de diciembre** a las **23:59 UTC+1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forma de entrega\n",
    "\n",
    "Se habilitará una tarea en nuestro Google Classroom a tal efecto para poder subir los ficheros finales. El formato de entrega puede ser en Jupyter Notebook (preferible) o en ficheros `.py` directamente y `.png` para los plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
